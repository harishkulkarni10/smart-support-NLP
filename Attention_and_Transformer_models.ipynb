{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7098001c05414aa1b834dd751f590f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_859ca65b87be4df4adb27dc3428b26c9",
              "IPY_MODEL_0bdc9a9a435c4c94aaf690520a7ce168",
              "IPY_MODEL_364088e8191d4c7cb98fb3f4c953a3bf"
            ],
            "layout": "IPY_MODEL_07e26b4a830f432fa9f9b1d0c7b8dd7d"
          }
        },
        "859ca65b87be4df4adb27dc3428b26c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d612d219b984ff8b9bea08d7d98a09b",
            "placeholder": "​",
            "style": "IPY_MODEL_05142ec25d0742deb4e075f583733659",
            "value": "Map: 100%"
          }
        },
        "0bdc9a9a435c4c94aaf690520a7ce168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a732c2ee8a5b4e4497233e16a6860a9c",
            "max": 15999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1a822f9c4984d568e2bfa047a00fc9d",
            "value": 15999
          }
        },
        "364088e8191d4c7cb98fb3f4c953a3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ea35da0f4984aa78b3cff53912c5e15",
            "placeholder": "​",
            "style": "IPY_MODEL_8a131bb3d4074f84ae63df8b01c877a4",
            "value": " 15999/15999 [00:05&lt;00:00, 2875.85 examples/s]"
          }
        },
        "07e26b4a830f432fa9f9b1d0c7b8dd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d612d219b984ff8b9bea08d7d98a09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05142ec25d0742deb4e075f583733659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a732c2ee8a5b4e4497233e16a6860a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a822f9c4984d568e2bfa047a00fc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ea35da0f4984aa78b3cff53912c5e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a131bb3d4074f84ae63df8b01c877a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb9d44a1d5c4908b1cd26aa3508d100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d305ffb35f2b4f62abdd9cdb467e31ee",
              "IPY_MODEL_21fc2af551374594a5829b554ddce797",
              "IPY_MODEL_9852af14f1104b9bb12fb1eb7c91e91f"
            ],
            "layout": "IPY_MODEL_f2d930235f704fa398950dff7c011cdb"
          }
        },
        "d305ffb35f2b4f62abdd9cdb467e31ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c52551003e47688b96aef5613e7935",
            "placeholder": "​",
            "style": "IPY_MODEL_d36f24784fd74a69aaf710cbf1354a37",
            "value": "Map: 100%"
          }
        },
        "21fc2af551374594a5829b554ddce797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a0d6ff6b4b84728b48f27488a47fc2d",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4e61859445456190ce663f211957d0",
            "value": 2000
          }
        },
        "9852af14f1104b9bb12fb1eb7c91e91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3bc36ac389468f88fadac6b65819f2",
            "placeholder": "​",
            "style": "IPY_MODEL_aed4b620295948009ce92e98a3ece231",
            "value": " 2000/2000 [00:00&lt;00:00, 2858.70 examples/s]"
          }
        },
        "f2d930235f704fa398950dff7c011cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c52551003e47688b96aef5613e7935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36f24784fd74a69aaf710cbf1354a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0d6ff6b4b84728b48f27488a47fc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4e61859445456190ce663f211957d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f3bc36ac389468f88fadac6b65819f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed4b620295948009ce92e98a3ece231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9d0ffe2e3cf441184253e73a0666e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f400cd1a809049c7afd2043e1973c414",
              "IPY_MODEL_c5f76a87c6ca48569ad40f0c579e5121",
              "IPY_MODEL_13a6b029e4a94d41a55b58db7ae8ebc0"
            ],
            "layout": "IPY_MODEL_3fed117c27b84cc3bd4123a796214af1"
          }
        },
        "f400cd1a809049c7afd2043e1973c414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a3b3eefa534118a83b9d24e4e3da8f",
            "placeholder": "​",
            "style": "IPY_MODEL_a5fb64214bb94321a5d1168c195b5ea1",
            "value": "Map: 100%"
          }
        },
        "c5f76a87c6ca48569ad40f0c579e5121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb26ac1fcdc4fb2ad747d26329d937a",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8de5dfc0a2eb4dd8a917fe01d037a91b",
            "value": 2000
          }
        },
        "13a6b029e4a94d41a55b58db7ae8ebc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d4d135857a4c0baed76f15c59e5cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_0f714d31a4ce4c2ba051c0a187793f2c",
            "value": " 2000/2000 [00:00&lt;00:00, 2928.06 examples/s]"
          }
        },
        "3fed117c27b84cc3bd4123a796214af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a3b3eefa534118a83b9d24e4e3da8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5fb64214bb94321a5d1168c195b5ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb26ac1fcdc4fb2ad747d26329d937a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de5dfc0a2eb4dd8a917fe01d037a91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20d4d135857a4c0baed76f15c59e5cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f714d31a4ce4c2ba051c0a187793f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81ae06d475241cd8d4f599dc2cbda84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beeb27d35a2f448984add452d80b457a",
              "IPY_MODEL_676c7f80717a4ce286d919c357749b41",
              "IPY_MODEL_aebc27e9d1fa4156b28b86f64055d6ec"
            ],
            "layout": "IPY_MODEL_4cd371a542ae4152b46f9e11879e580e"
          }
        },
        "beeb27d35a2f448984add452d80b457a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49740c1212514de4891881d5096b77a1",
            "placeholder": "​",
            "style": "IPY_MODEL_fc145f7d76954941a9ed19633b9d050d",
            "value": "Map: 100%"
          }
        },
        "676c7f80717a4ce286d919c357749b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf2b866abd24d5b8076c9323fbe5181",
            "max": 383512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f82c73a9d169454f863c4b3bd06f09a6",
            "value": 383512
          }
        },
        "aebc27e9d1fa4156b28b86f64055d6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c8085b3e2449f58055b7419e222540",
            "placeholder": "​",
            "style": "IPY_MODEL_534bcb02b46447be93c74f65ddc79bc5",
            "value": " 383512/383512 [02:28&lt;00:00, 1906.69 examples/s]"
          }
        },
        "4cd371a542ae4152b46f9e11879e580e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49740c1212514de4891881d5096b77a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc145f7d76954941a9ed19633b9d050d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf2b866abd24d5b8076c9323fbe5181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82c73a9d169454f863c4b3bd06f09a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39c8085b3e2449f58055b7419e222540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534bcb02b46447be93c74f65ddc79bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa30d43cb84b4de68f2173a90e98eba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1fe86f253794fc8ae62a8024fc1dcf8",
              "IPY_MODEL_9288ca9ce04546f4b88201cbc840d7ab",
              "IPY_MODEL_a9923c5fc85f43a2ba21a28c972e4363"
            ],
            "layout": "IPY_MODEL_5ec0a3313c5a4bc2a868e175cbf1869a"
          }
        },
        "f1fe86f253794fc8ae62a8024fc1dcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07979f656c34293aa60cacc15477e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_16ef0930dfc641f1bfe6727c556c73e6",
            "value": "Map: 100%"
          }
        },
        "9288ca9ce04546f4b88201cbc840d7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669a411822c44e3d80ebec9bd49e236c",
            "max": 383512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa600e2bc3dc427cbeaa1d2650e93809",
            "value": 383512
          }
        },
        "a9923c5fc85f43a2ba21a28c972e4363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456a5d8e75e9410c8c200e657fc030d6",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba8f997ebac4bd09185ce1ce594d303",
            "value": " 383512/383512 [03:40&lt;00:00, 2731.47 examples/s]"
          }
        },
        "5ec0a3313c5a4bc2a868e175cbf1869a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07979f656c34293aa60cacc15477e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ef0930dfc641f1bfe6727c556c73e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "669a411822c44e3d80ebec9bd49e236c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa600e2bc3dc427cbeaa1d2650e93809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "456a5d8e75e9410c8c200e657fc030d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba8f997ebac4bd09185ce1ce594d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview and Current Focus\n",
        "\n",
        "## What We've Accomplished So Far\n",
        "\n",
        "- **Data Preparation:** Loaded CFPB consumer complaint data, performed cleaning, preprocessing, and feature engineering of complaint narratives.\n",
        "- **Sampling:** Created a 20k sample demo dataset, initially with original class imbalance, later re-sampled to ensure balanced class representation for robust model evaluation.\n",
        "- **Text Representation:** Tokenized complaint narratives and generated padded sequences (max length = 200) using Keras Tokenizer.\n",
        "- **Embeddings:** Downloaded and aligned pre-trained FastText word vectors with the vocabulary for these complaints, resulting in a complete embedding matrix.\n",
        "- **Classic and Deep Learning Models:** Built and compared a variety of models for product classification:\n",
        "    - **Feedforward Neural Network:** Performed poorly/underfit, confirming the need for sequential/contextual architectures.\n",
        "    - **BiLSTM/CNN (with FastText):** Achieved moderate-to-good accuracy on majority classes, but struggled with rare classes due to imbalance.\n",
        "    - **Class-Weighted Models:** Tried class weights to address imbalance—improved recall for minority classes, but reduced overall accuracy and precision.\n",
        "- **Evaluation & Interpretation:** Performed detailed error analysis, learning curve interpretation, and confusion matrix breakdown to understand each model's strengths and limitations.\n",
        "\n",
        "## What We Are Doing Next\n",
        "\n",
        "- **Goal:** Advance to state-of-the-art deep learning by implementing two modern NLP approaches:\n",
        "    1. **BiLSTM + Attention:** Add a custom Attention layer on top of BiLSTM using balanced data and FastText embeddings to improve focus on relevant tokens and interpretability.\n",
        "    2. **Transformer Fine-Tuning:** Fine-tune a pre-trained language model (RoBERTa/DistilBERT) on our product classification task for SOTA performance.\n",
        "\n",
        "- **Objectives:**\n",
        "    - Compare attention-enhanced BiLSTM vs vanilla BiLSTM performance on balanced data.\n",
        "    - Demonstrate modern transformer fine-tuning skills and achieve best possible classification metrics.\n",
        "    - Evaluate interpretability through attention weights and model comparison across all architectures.\n",
        "    - Create comprehensive model comparison showcasing progression from classic ML to modern transformers.\n",
        "\n",
        "- **Context:** This completes our NLP pipeline progression from traditional embeddings through deep learning to transformer models, demonstrating full-stack data science and modern NLP expertise for portfolio/interview purposes.\n"
      ],
      "metadata": {
        "id": "j25RyLHxa1dh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "872ab17e",
        "outputId": "aab1d6f2-d768-45fc-b1ad-66257478ffe3"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooAakcOSW859",
        "outputId": "953b7084-e8b0-4801-d4b6-9f09cf54df01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "FastText model already extracted to /content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major/embeddings. Skipping extraction.\n",
            "FastText model loaded from /content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major/embeddings/fasttext-wiki-news-subwords-300.kv.\n",
            "Embedding matrix created: shape=(23324, 300), OOV words=5716/23323 (24.51%)\n",
            "20k embedding matrix and tokenizer saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "load_path = '/content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major'\n",
        "\n",
        "cleaned_data = pd.read_parquet(os.path.join(load_path, 'cleaned_data.parquet'))\n",
        "\n",
        "# SAMPLE ONLY 20k\n",
        "demo_data = cleaned_data.sample(20000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "demo_data.to_csv(os.path.join(load_path, 'demo_data_20k.csv'), index=False)\n",
        "\n",
        "import zipfile, gensim\n",
        "ft_zip = os.path.join(load_path, 'embeddings/fasttext-wiki-news-subwords-300.kv.zip')\n",
        "ft_extracted_path = os.path.join(load_path, 'embeddings')\n",
        "ft_file = os.path.join(ft_extracted_path, 'fasttext-wiki-news-subwords-300.kv')\n",
        "\n",
        "if os.path.exists(ft_zip):\n",
        "    if not os.path.exists(ft_file):\n",
        "        print(f\"Extracting {os.path.basename(ft_zip)} to {ft_extracted_path}...\")\n",
        "        with zipfile.ZipFile(ft_zip, 'r') as zipf:\n",
        "            zipf.extractall(ft_extracted_path)\n",
        "        print(\"Extraction complete.\")\n",
        "    else:\n",
        "        print(f\"FastText model already extracted to {ft_extracted_path}. Skipping extraction.\")\n",
        "\n",
        "    try:\n",
        "        ft_model = gensim.models.KeyedVectors.load(ft_file, mmap='r') # Load from the correct path\n",
        "        print(f\"FastText model loaded from {ft_file}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading FastText model from {ft_file}: {e}\")\n",
        "        # Handle the error or exit if the model is essential\n",
        "else:\n",
        "    print(f\"Error: Zip file not found at {ft_zip}\")\n",
        "    # Handle the error or exit if the zip file is essential\n",
        "\n",
        "\n",
        "# Tokenizer and sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(demo_data['cleaned_narrative'])\n",
        "sequences = tokenizer.texts_to_sequences(demo_data['cleaned_narrative'])\n",
        "max_len = 200\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Embedding matrix\n",
        "import numpy as np\n",
        "import joblib # Import joblib for saving the tokenizer\n",
        "\n",
        "if 'ft_model' in locals(): # Proceed only if the model was loaded successfully\n",
        "    embedding_dim = ft_model.vector_size  # 300\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim), dtype='float32')\n",
        "    oov_count = 0\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        if i >= vocab_size:\n",
        "            continue\n",
        "        try:\n",
        "            embedding_matrix[i] = ft_model[word]\n",
        "        except KeyError:\n",
        "            oov_count += 1\n",
        "\n",
        "    print(f\"Embedding matrix created: shape={embedding_matrix.shape}, OOV words={oov_count}/{vocab_size-1} ({oov_count/(vocab_size-1)*100:.2f}%)\")\n",
        "\n",
        "    # SAVE ARTIFACTS\n",
        "    np.save(os.path.join(load_path, 'fasttext_embedding_matrix_20k.npy'), embedding_matrix)\n",
        "    joblib.dump(tokenizer, os.path.join(load_path, 'tokenizer_fasttext_20k.joblib'))\n",
        "    print(\"20k embedding matrix and tokenizer saved.\")\n",
        "else:\n",
        "    print(\"FastText model not loaded. Skipping embedding matrix creation and saving.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Encoding\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(demo_data['Product'])\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Info\n",
        "print(f\"Number of product classes: {len(label_encoder.classes_)}\")\n",
        "print(f\"Sample encoded labels: {y_encoded[:10]}\")\n",
        "print(f\"One-hot shape: {y_categorical.shape}\")\n",
        "\n",
        "# class distribution\n",
        "class_dist = pd.Series(y_encoded).value_counts().sort_index()\n",
        "for idx, count in class_dist.items():\n",
        "    print(f\"{label_encoder.classes_[idx]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csJosZnLZ8EO",
        "outputId": "43f8a6d0-af71-4bb6-b4a4-db51b6757e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of product classes: 18\n",
            "Sample encoded labels: [15  5  5  3  6  6  3  7  6  6]\n",
            "One-hot shape: \n",
            "(20000, 18)\n",
            "Bank account or service: 748\n",
            "Checking or savings account: 680\n",
            "Consumer Loan: 498\n",
            "Credit card: 942\n",
            "Credit card or prepaid card: 1174\n",
            "Credit reporting: 1634\n",
            "Credit reporting, credit repair services, or other personal consumer reports: 4845\n",
            "Debt collection: 4442\n",
            "Money transfer, virtual currency, or money service: 293\n",
            "Money transfers: 86\n",
            "Mortgage: 2804\n",
            "Other financial service: 13\n",
            "Payday loan: 101\n",
            "Payday loan, title loan, or personal loan: 225\n",
            "Prepaid card: 72\n",
            "Student loan: 1137\n",
            "Vehicle loan or lease: 305\n",
            "Virtual currency: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Find the index of the \"Virtual currency\" class\n",
        "virtual_currency_index = label_encoder.transform(['Virtual currency'])[0]\n",
        "\n",
        "# Filter out samples belonging to the \"Virtual currency\" class\n",
        "filtered_indices = np.where(y_encoded != virtual_currency_index)[0]\n",
        "X_filtered = padded_sequences[filtered_indices]\n",
        "y_filtered = y_categorical[filtered_indices]\n",
        "y_encoded_filtered = y_encoded[filtered_indices]\n",
        "\n",
        "\n",
        "# First split: separate test set (20%) from filtered data\n",
        "X_temp, X_test, y_temp, y_test, y_temp_encoded, y_test_encoded = train_test_split(\n",
        "    X_filtered, y_filtered, y_encoded_filtered,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded_filtered # Stratify based on filtered encoded labels\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val, y_train_encoded, y_val_encoded = train_test_split(\n",
        "    X_temp, y_temp, y_temp_encoded,\n",
        "    test_size=0.1875, # (0.15 / 0.80) of original data\n",
        "    random_state=42,\n",
        "    stratify=y_temp_encoded # Stratify based on encoded labels of the temporary set\n",
        ")\n",
        "\n",
        "\n",
        "# Display split info\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Total: {X_train.shape[0] + X_val.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"\\nX_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"Number of classes: {y_train.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnHaK9D6cqe1",
        "outputId": "26944afb-cdc6-4ad8-d45c-82c2ad6527cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 12999 samples\n",
            "Validation set: 3000 samples\n",
            "Test set: 4000 samples\n",
            "Total: 19999\n",
            "\n",
            "X_train shape: (12999, 200)\n",
            "y_train shape: (12999, 18)\n",
            "Number of classes: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Attention layer\n",
        "from tensorflow.keras.layers import Layer, Input\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class Attention(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(Attention, self).__init__(**kwargs)\n",
        "  def build(self, input_shape):\n",
        "    self.W = self.add_weight(name='att_weight',\n",
        "                             shape=(input_shape[-1], 1),\n",
        "                             initializer='normal',\n",
        "                             trainable=True)\n",
        "    super().build(input_shape)\n",
        "  def call(self, x):\n",
        "    e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W))\n",
        "    a = tf.keras.backend.softmax(e, axis=1)\n",
        "    output = x * a\n",
        "    return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "# Calculate Class Weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "class_weights_arr = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_int),\n",
        "    y=y_train_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights_arr))\n",
        "\n",
        "print(\"Class weights dictionary:\")\n",
        "for k, v in class_weight_dict.items():\n",
        "    print(f\"Class {k} ({label_encoder.classes_[k]}): {v:.3f}\")\n",
        "\n",
        "# Model Construction\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "\n",
        "input_seq = Input(shape = (X_train.shape[1],))\n",
        "embedding_layer = Embedding(\n",
        "    input_dim = embedding_matrix.shape[0],\n",
        "    output_dim = embedding_matrix.shape[1],\n",
        "    weights = [embedding_matrix],\n",
        "    trainable = False\n",
        ")(input_seq)\n",
        "\n",
        "bilstm_out = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
        "attn_out = Attention()(bilstm_out)\n",
        "drop1 = Dropout(0.4)(attn_out)\n",
        "dense = Dense(64, activation = 'relu')(drop1)\n",
        "drop2 = Dropout(0.3)(dense)\n",
        "output = Dense(y_train.shape[1], activation = 'softmax')(drop2)\n",
        "\n",
        "model = Model(inputs = input_seq, outputs = output)\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Model Training\n",
        "print('\\nStarting training with class weights...')\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = 8,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val, y_val),\n",
        "    class_weight = class_weight_dict,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"\\nEvaluating model on test set...\")\n",
        "y_test_pred_prob = model.predict(X_test)\n",
        "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Create a list of target names excluding 'Virtual currency'\n",
        "target_names_filtered = [name for name in label_encoder.classes_ if name != 'Virtual currency']\n",
        "\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_true, y_test_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_true, y_test_pred, target_names=target_names_filtered))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "print(cm)\n",
        "\n",
        "# --- Save Model ---\n",
        "model.save('bilstm_attention_model.h5')\n",
        "print(\"\\nModel saved as 'bilstm_attention_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "whZOPCMTh6Ty",
        "outputId": "b7b61775-eeb9-4567-bf7a-fa14b7a673f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights dictionary:\n",
            "Class 0 (Bank account or service): 1.573\n",
            "Class 1 (Checking or savings account): 1.730\n",
            "Class 2 (Consumer Loan): 2.367\n",
            "Class 3 (Credit card): 1.247\n",
            "Class 4 (Credit card or prepaid card): 1.002\n",
            "Class 5 (Credit reporting): 0.720\n",
            "Class 6 (Credit reporting, credit repair services, or other personal consumer reports): 0.243\n",
            "Class 7 (Debt collection): 0.265\n",
            "Class 8 (Money transfer, virtual currency, or money service): 4.024\n",
            "Class 9 (Money transfers): 13.654\n",
            "Class 10 (Mortgage): 0.419\n",
            "Class 11 (Other financial service): 95.581\n",
            "Class 12 (Payday loan): 11.586\n",
            "Class 13 (Payday loan, title loan, or personal loan): 5.237\n",
            "Class 14 (Prepaid card): 16.269\n",
            "Class 15 (Student loan): 1.035\n",
            "Class 16 (Vehicle loan or lease): 3.862\n",
            "\n",
            "Model Architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m6,997,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m186,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m1,170\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,997,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,193,634\u001b[0m (27.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,193,634</span> (27.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m196,434\u001b[0m (767.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,434</span> (767.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,997,200\u001b[0m (26.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,997,200</span> (26.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training with class weights...\n",
            "Epoch 1/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.0760 - loss: 2.8154 - val_accuracy: 0.2553 - val_loss: 2.7433\n",
            "Epoch 2/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.1312 - loss: 2.8263 - val_accuracy: 0.1800 - val_loss: 2.5903\n",
            "Epoch 3/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.2229 - loss: 2.6509 - val_accuracy: 0.1973 - val_loss: 2.5138\n",
            "Epoch 4/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.2383 - loss: 2.6525 - val_accuracy: 0.2057 - val_loss: 2.1387\n",
            "Epoch 5/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.2555 - loss: 2.3972 - val_accuracy: 0.3230 - val_loss: 2.1474\n",
            "Epoch 6/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.2672 - loss: 2.2660 - val_accuracy: 0.2693 - val_loss: 2.0074\n",
            "Epoch 7/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.2710 - loss: 2.2434 - val_accuracy: 0.3337 - val_loss: 1.9449\n",
            "Epoch 8/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.2960 - loss: 2.1109 - val_accuracy: 0.3333 - val_loss: 1.8877\n",
            "\n",
            "Evaluating model on test set...\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.3255\n",
            "\n",
            "Classification Report:\n",
            "                                                                              precision    recall  f1-score   support\n",
            "\n",
            "                                                     Bank account or service       0.50      0.01      0.03       150\n",
            "                                                 Checking or savings account       0.30      0.52      0.38       136\n",
            "                                                               Consumer Loan       0.08      0.12      0.09       100\n",
            "                                                                 Credit card       0.31      0.09      0.13       188\n",
            "                                                 Credit card or prepaid card       0.30      0.23      0.26       235\n",
            "                                                            Credit reporting       0.19      0.74      0.30       327\n",
            "Credit reporting, credit repair services, or other personal consumer reports       0.34      0.04      0.07       969\n",
            "                                                             Debt collection       0.57      0.45      0.50       888\n",
            "                          Money transfer, virtual currency, or money service       0.33      0.03      0.06        59\n",
            "                                                             Money transfers       0.08      0.53      0.14        17\n",
            "                                                                    Mortgage       0.74      0.57      0.64       561\n",
            "                                                     Other financial service       0.00      0.00      0.00         3\n",
            "                                                                 Payday loan       0.05      0.25      0.08        20\n",
            "                                   Payday loan, title loan, or personal loan       0.00      0.00      0.00        45\n",
            "                                                                Prepaid card       0.05      0.64      0.09        14\n",
            "                                                                Student loan       0.39      0.55      0.46       227\n",
            "                                                       Vehicle loan or lease       0.08      0.05      0.06        61\n",
            "\n",
            "                                                                    accuracy                           0.33      4000\n",
            "                                                                   macro avg       0.25      0.28      0.19      4000\n",
            "                                                                weighted avg       0.42      0.33      0.31      4000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  2  88   0   0   5   5   3   1   2  13   2   8   1   1  16   0   3]\n",
            " [  2  71   2   1   4  11   2   2   1  20   0   5   0   0  14   0   1]\n",
            " [  0   0  12   0   2   8   0  20   0   1  22   7   5   0   0  17   6]\n",
            " [  0  11   6  16  40  20  12   9   0   7   1   5   2   1  55   3   0]\n",
            " [  0  18   2  11  53  18  12  19   0  12   2   4   3   0  76   3   2]\n",
            " [  0   1   4   3  10 243  12  39   0   3   3   0   3   0   2   4   0]\n",
            " [  0  12  21  14  34 646  36 124   0   4  16   2  15   1   5  37   2]\n",
            " [  0   8  23   6  19 325  24 400   0   8  16   5  17   2   4  26   5]\n",
            " [  0  15   1   0   6   4   0   1   2  22   0   3   0   0   4   0   1]\n",
            " [  0   0   1   0   1   1   0   0   1   9   0   1   0   0   3   0   0]\n",
            " [  0   2  53   0   2  14   2  42   0   5 317  14  30   0   0  70  10]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0]\n",
            " [  0   0   2   0   0   2   0   2   0   0   1   2   5   1   0   5   0]\n",
            " [  0   1   2   0   0   0   1   1   0   2   9   5   4   0   0  18   2]\n",
            " [  0   2   0   0   1   0   0   0   0   2   0   0   0   0   9   0   0]\n",
            " [  0   2  20   0   1   4   2  33   0   1  15   2  22   0   0 124   1]\n",
            " [  0   1   7   0   1   3   0   7   0   0  24   5   2   0   0   8   3]]\n",
            "\n",
            "Model saved as 'bilstm_attention_model.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b284fa3e",
        "outputId": "e12bb4d3-b0a7-472f-90e2-5a66fb839b16"
      },
      "source": [
        "# Model Construction (without class weights)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Input\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Re-define the Attention layer if it's not globally available (or ensure it is)\n",
        "class Attention(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(Attention, self).__init__(**kwargs)\n",
        "  def build(self, input_shape):\n",
        "    self.W = self.add_weight(name='att_weight',\n",
        "                             shape=(input_shape[-1], 1),\n",
        "                             initializer='normal',\n",
        "                             trainable=True)\n",
        "    super().build(input_shape)\n",
        "  def call(self, x):\n",
        "    e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W))\n",
        "    a = tf.keras.backend.softmax(e, axis=1)\n",
        "    output = x * a\n",
        "    return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "\n",
        "input_seq = Input(shape = (X_train.shape[1],))\n",
        "embedding_layer = Embedding(\n",
        "    input_dim = embedding_matrix.shape[0],\n",
        "    output_dim = embedding_matrix.shape[1],\n",
        "    weights = [embedding_matrix],\n",
        "    trainable = False\n",
        ")(input_seq)\n",
        "\n",
        "bilstm_out = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
        "attn_out = Attention()(bilstm_out)\n",
        "drop1 = Dropout(0.4)(attn_out)\n",
        "dense = Dense(64, activation = 'relu')(drop1)\n",
        "drop2 = Dropout(0.3)(dense)\n",
        "output = Dense(y_train.shape[1], activation = 'softmax')(drop2)\n",
        "\n",
        "model_no_weights = Model(inputs = input_seq, outputs = output)\n",
        "model_no_weights.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Architecture (without class weights):\")\n",
        "model_no_weights.summary()\n",
        "\n",
        "# Model Training (without class weights)\n",
        "print('\\nStarting training without class weights...')\n",
        "history_no_weights = model_no_weights.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = 8,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val, y_val),\n",
        "    verbose = 1 # Removed class_weight\n",
        ")\n",
        "\n",
        "# Model Evaluation (without class weights)\n",
        "print(\"\\nEvaluating model without class weights on test set...\")\n",
        "y_test_pred_prob_no_weights = model_no_weights.predict(X_test)\n",
        "y_test_pred_no_weights = np.argmax(y_test_pred_prob_no_weights, axis=1)\n",
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Create a list of target names excluding 'Virtual currency'\n",
        "target_names_filtered = [name for name in label_encoder.classes_ if name != 'Virtual currency']\n",
        "\n",
        "print(f\"\\nTest Accuracy (without class weights): {accuracy_score(y_test_true, y_test_pred_no_weights):.4f}\")\n",
        "print(\"\\nClassification Report (without class weights):\")\n",
        "print(classification_report(y_test_true, y_test_pred_no_weights, target_names=target_names_filtered))\n",
        "\n",
        "print(\"\\nConfusion Matrix (without class weights):\")\n",
        "cm_no_weights = confusion_matrix(y_test_true, y_test_pred_no_weights)\n",
        "print(cm_no_weights)\n",
        "\n",
        "# --- Save Model ---\n",
        "model_no_weights.save('bilstm_attention_model_no_weights.h5')\n",
        "print(\"\\nModel saved as 'bilstm_attention_model_no_weights.h5'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Architecture (without class weights):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m6,997,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m186,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m1,170\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,997,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,193,634\u001b[0m (27.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,193,634</span> (27.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m196,434\u001b[0m (767.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,434</span> (767.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,997,200\u001b[0m (26.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,997,200</span> (26.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training without class weights...\n",
            "Epoch 1/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.2173 - loss: 2.5307 - val_accuracy: 0.3607 - val_loss: 2.0238\n",
            "Epoch 2/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.3362 - loss: 2.0861 - val_accuracy: 0.3417 - val_loss: 1.9541\n",
            "Epoch 3/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3345 - loss: 1.9266 - val_accuracy: 0.4260 - val_loss: 1.7097\n",
            "Epoch 4/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.4402 - loss: 1.6962 - val_accuracy: 0.5033 - val_loss: 1.5365\n",
            "Epoch 5/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4948 - loss: 1.5377 - val_accuracy: 0.5340 - val_loss: 1.4425\n",
            "Epoch 6/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5162 - loss: 1.4870 - val_accuracy: 0.5563 - val_loss: 1.3799\n",
            "Epoch 7/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5508 - loss: 1.3995 - val_accuracy: 0.5563 - val_loss: 1.3716\n",
            "Epoch 8/8\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5506 - loss: 1.3691 - val_accuracy: 0.5460 - val_loss: 1.3994\n",
            "\n",
            "Evaluating model without class weights on test set...\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy (without class weights): 0.5308\n",
            "\n",
            "Classification Report (without class weights):\n",
            "                                                                              precision    recall  f1-score   support\n",
            "\n",
            "                                                     Bank account or service       0.28      0.38      0.32       150\n",
            "                                                 Checking or savings account       0.36      0.17      0.23       136\n",
            "                                                               Consumer Loan       0.00      0.00      0.00       100\n",
            "                                                                 Credit card       0.62      0.03      0.05       188\n",
            "                                                 Credit card or prepaid card       0.39      0.33      0.36       235\n",
            "                                                            Credit reporting       0.00      0.00      0.00       327\n",
            "Credit reporting, credit repair services, or other personal consumer reports       0.56      0.71      0.62       969\n",
            "                                                             Debt collection       0.61      0.75      0.67       888\n",
            "                          Money transfer, virtual currency, or money service       0.00      0.00      0.00        59\n",
            "                                                             Money transfers       0.00      0.00      0.00        17\n",
            "                                                                    Mortgage       0.50      0.91      0.65       561\n",
            "                                                     Other financial service       0.00      0.00      0.00         3\n",
            "                                                                 Payday loan       0.00      0.00      0.00        20\n",
            "                                   Payday loan, title loan, or personal loan       0.00      0.00      0.00        45\n",
            "                                                                Prepaid card       0.00      0.00      0.00        14\n",
            "                                                                Student loan       0.50      0.47      0.48       227\n",
            "                                                       Vehicle loan or lease       0.00      0.00      0.00        61\n",
            "\n",
            "                                                                    accuracy                           0.53      4000\n",
            "                                                                   macro avg       0.23      0.22      0.20      4000\n",
            "                                                                weighted avg       0.45      0.53      0.46      4000\n",
            "\n",
            "\n",
            "Confusion Matrix (without class weights):\n",
            "[[ 57  23   0   0   7   0   8   6   0   0  49   0   0   0   0   0   0]\n",
            " [ 44  23   0   0   6   0   5  11   0   0  47   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0  15  24   0   0  40   0   0   0   0  19   0]\n",
            " [ 27   1   1   5  69   0  27  35   0   0  22   0   0   0   0   1   0]\n",
            " [ 45   4   0   3  78   0  37  39   0   0  28   0   0   0   0   1   0]\n",
            " [  0   0   0   0   2   0 270  40   0   0  13   0   0   0   0   2   0]\n",
            " [  4   1   0   0  17   0 684 167   0   0  66   0   0   0   0  30   0]\n",
            " [  2   1   0   0  11   0 141 662   0   0  55   0   0   0   0  16   0]\n",
            " [ 12   9   0   0   4   0   2   5   0   0  27   0   0   0   0   0   0]\n",
            " [  3   1   0   0   0   0   0   7   0   0   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  13  31   0   0 508   0   0   0   0   9   0]\n",
            " [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   1   7   0   0   9   0   0   0   0   3   0]\n",
            " [  1   0   0   0   0   0   2   8   0   0  19   0   0   0   0  15   0]\n",
            " [  1   0   0   0   6   0   0   1   0   0   6   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0  12  25   0   0  82   0   0   0   0 106   0]\n",
            " [  0   0   1   0   0   0   8  11   0   0  31   0   0   0   0  10   0]]\n",
            "\n",
            "Model saved as 'bilstm_attention_model_no_weights.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ad827d"
      },
      "source": [
        "## Project Progress Summary\n",
        "\n",
        "This notebook chronicles our journey in building and evaluating models for classifying consumer complaints. Following our initial data preparation and exploration, we focused on building and comparing different modeling approaches:\n",
        "\n",
        "*   We started with **classic and deep learning models**, including a Feedforward Neural Network and a BiLSTM/CNN, using FastText embeddings. These initial models provided a baseline and highlighted the challenges of classifying imbalanced text data.\n",
        "*   We then advanced to a **BiLSTM with a custom Attention layer**, experimenting with and without class weights to understand their impact on model performance, particularly for less frequent classes. These experiments offered valuable insights into improving model focus and handling data imbalance in deep learning architectures.\n",
        "\n",
        "Having explored these approaches and evaluated their performance, we are now ready to advance to state-of-the-art techniques. The next phase of this project will involve **fine-tuning a pre-trained transformer model, specifically DistilBERT**, to leverage its advanced language understanding capabilities for potentially achieving the best possible classification metrics on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "load_path = '/content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major'\n",
        "\n",
        "if os.path.exists(os.path.join(load_path, 'demo_data_20k.csv')):\n",
        "    demo_data = pd.read_csv(os.path.join(load_path, 'demo_data_20k.csv'))\n",
        "    print(f\"Loaded existing demo_data_20k.csv: {demo_data.shape}\")\n",
        "else:\n",
        "    cleaned_data = pd.read_parquet(os.path.join(load_path, 'cleaned_data.parquet'))\n",
        "    demo_data = cleaned_data.sample(20000, random_state=42).reset_index(drop=True)\n",
        "    demo_data.to_csv(os.path.join(load_path, 'demo_data_20k.csv'), index=False)\n",
        "    print(f\"Created demo_data_20k.csv: {demo_data.shape}\")\n",
        "\n",
        "print(f\"Columns: {list(demo_data.columns)}\")\n",
        "print(f\"Product classes: {demo_data['Product'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz11c7Z4iNYi",
        "outputId": "ef0b02ef-426d-4717-8c66-33c3e0908084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded existing demo_data_20k.csv: (20000, 20)\n",
            "Columns: ['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue', 'Consumer complaint narrative', 'Company public response', 'Company', 'State', 'ZIP code', 'Tags', 'Consumer consent provided?', 'Submitted via', 'Date sent to company', 'Company response to consumer', 'Timely response?', 'Consumer disputed?', 'Complaint ID', 'narrative_length', 'cleaned_narrative']\n",
            "Product classes: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset, DatasetDict"
      ],
      "metadata": {
        "id": "Nz28sa5KLBQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "print(\"1. Loading data ....\")\n",
        "demo_data = pd.read_csv('/content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major/demo_data_20k.csv')\n",
        "print(f\"Data shape: {demo_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OudTp1fjLBSm",
        "outputId": "3f18b6bd-af5f-4f35-e71a-5feecf0ca0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading data ....\n",
            "Data shape: (20000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 2. Subsample and Filter\n",
        "# print(\"2. Subsampling and Filtering data ....\")\n",
        "# grouped = demo_data.groupby('Product', group_keys=False)\n",
        "# # Subsample, then filter out groups with less than 2 samples for stratification\n",
        "# subset = grouped.apply(lambda x: x.sample(min(len(x), 200), random_state=42)).groupby('Product').filter(lambda x: len(x) >= 2)\n",
        "# print(f\"Subset shape after filtering: {subset.shape}\")\n",
        "# print(f\"Product classes in subset: {subset['Product'].nunique()}\")\n",
        "\n",
        "# Use the full demo_data as subsampling gave very less data\n",
        "subset = demo_data\n",
        "print(f\"Using full data: {subset.shape}\")\n",
        "print(f\"Product classes in data: {subset['Product'].nunique()}\")\n",
        "\n",
        "# Filter out classes with less than 2 samples for stratification\n",
        "product_counts = subset['Product'].value_counts()\n",
        "classes_to_keep = product_counts[product_counts >= 2].index\n",
        "subset = subset[subset['Product'].isin(classes_to_keep)]\n",
        "print(f\"Subset shape after filtering for stratification: {subset.shape}\")\n",
        "print(f\"Product classes in subset after filtering for stratification: {subset['Product'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDe2E3ksLBUq",
        "outputId": "2eda6a8f-1be6-41db-8fbc-abef959df0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using full data: (20000, 20)\n",
            "Product classes in data: 18\n",
            "Subset shape after filtering for stratification: (19999, 20)\n",
            "Product classes in subset after filtering for stratification: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Split data\n",
        "print(\"3. Splitting data ....\")\n",
        "# Stratify based on the filtered subset['Product']\n",
        "train_df, temp_df = train_test_split(subset, test_size=0.2, stratify=subset['Product'], random_state=42)\n",
        "# Stratify the second split based on the temporary dataframe's product column\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Product'], random_state=42)\n",
        "print(f\"Train: {train_df.shape} | Val: {val_df.shape} | Test: {test_df.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y_Z0ztiLBWw",
        "outputId": "7c2be161-08bc-4f59-926f-094921081b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Splitting data ....\n",
            "Train: (15999, 20) | Val: (2000, 20) | Test: (2000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Label encoding\n",
        "print(\"4. Label encoding ....\")\n",
        "label_encoder = LabelEncoder()\n",
        "# Fit the encoder on the product names present in the filtered subset\n",
        "label_encoder.fit(subset['Product'])\n",
        "\n",
        "# Transform the 'Product' column to numerical labels for all dataframes\n",
        "train_df['label'] = label_encoder.transform(train_df['Product'])\n",
        "val_df['label'] = label_encoder.transform(val_df['Product'])\n",
        "test_df['label'] = label_encoder.transform(test_df['Product'])\n",
        "num_labels = len(label_encoder.classes_)\n",
        "print(f\"Number of classes for training: {num_labels}\")\n",
        "print(f\"Label classes for training: {list(label_encoder.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6XpaLoiLIZ0",
        "outputId": "12cf371d-5e42-4bb1-ec53-2856f6bc54e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Label encoding ....\n",
            "Number of classes for training: 17\n",
            "Label classes for training: ['Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Credit card', 'Credit card or prepaid card', 'Credit reporting', 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Mortgage', 'Other financial service', 'Payday loan', 'Payday loan, title loan, or personal loan', 'Prepaid card', 'Student loan', 'Vehicle loan or lease']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Tokenization\n",
        "print(\"Initializing tokenizer ....\")\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "def tokenize_function(batch):\n",
        "  if 'cleaned_narrative' not in batch:\n",
        "      raise ValueError(\"Batch does not contain 'cleaned_narrative' column.\")\n",
        "  return tokenizer(batch['cleaned_narrative'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "print(\"Tokenizing datasets ....\")\n",
        "# Create Dataset objects from pandas DataFrames, including the 'label' column\n",
        "train_ds = Dataset.from_pandas(train_df[['cleaned_narrative', 'label']])\n",
        "val_ds = Dataset.from_pandas(val_df[['cleaned_narrative', 'label']])\n",
        "test_ds = Dataset.from_pandas(test_df[['cleaned_narrative', 'label']])\n",
        "\n",
        "# Map the tokenization function over the datasets\n",
        "train_ds = train_ds.map(tokenize_function, batched=True)\n",
        "val_ds = val_ds.map(tokenize_function, batched=True)\n",
        "test_ds = test_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format to PyTorch tensors, specifying the columns to keep\n",
        "train_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "print(\"Tokenization done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "7098001c05414aa1b834dd751f590f10",
            "859ca65b87be4df4adb27dc3428b26c9",
            "0bdc9a9a435c4c94aaf690520a7ce168",
            "364088e8191d4c7cb98fb3f4c953a3bf",
            "07e26b4a830f432fa9f9b1d0c7b8dd7d",
            "9d612d219b984ff8b9bea08d7d98a09b",
            "05142ec25d0742deb4e075f583733659",
            "a732c2ee8a5b4e4497233e16a6860a9c",
            "a1a822f9c4984d568e2bfa047a00fc9d",
            "1ea35da0f4984aa78b3cff53912c5e15",
            "8a131bb3d4074f84ae63df8b01c877a4",
            "9fb9d44a1d5c4908b1cd26aa3508d100",
            "d305ffb35f2b4f62abdd9cdb467e31ee",
            "21fc2af551374594a5829b554ddce797",
            "9852af14f1104b9bb12fb1eb7c91e91f",
            "f2d930235f704fa398950dff7c011cdb",
            "87c52551003e47688b96aef5613e7935",
            "d36f24784fd74a69aaf710cbf1354a37",
            "4a0d6ff6b4b84728b48f27488a47fc2d",
            "aa4e61859445456190ce663f211957d0",
            "3f3bc36ac389468f88fadac6b65819f2",
            "aed4b620295948009ce92e98a3ece231",
            "e9d0ffe2e3cf441184253e73a0666e64",
            "f400cd1a809049c7afd2043e1973c414",
            "c5f76a87c6ca48569ad40f0c579e5121",
            "13a6b029e4a94d41a55b58db7ae8ebc0",
            "3fed117c27b84cc3bd4123a796214af1",
            "15a3b3eefa534118a83b9d24e4e3da8f",
            "a5fb64214bb94321a5d1168c195b5ea1",
            "dfb26ac1fcdc4fb2ad747d26329d937a",
            "8de5dfc0a2eb4dd8a917fe01d037a91b",
            "20d4d135857a4c0baed76f15c59e5cb7",
            "0f714d31a4ce4c2ba051c0a187793f2c"
          ]
        },
        "id": "V8bo_8ZrLQJU",
        "outputId": "35f31c6a-f5a6-49b4-ebb8-8139ce760b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing tokenizer ....\n",
            "Tokenizing datasets ....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7098001c05414aa1b834dd751f590f10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fb9d44a1d5c4908b1cd26aa3508d100"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9d0ffe2e3cf441184253e73a0666e64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Load model\n",
        "print(\"Loading DistilBERT model ....\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfJoRfHgLRzG",
        "outputId": "a75f617f-5ab7-4aa2-9fd3-6bba7f9f0e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DistilBERT model ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Training arguments and trainer setup\n",
        "output_dir = f\"./distilbert-finetuned-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "print(f\"Output directory = {output_dir}\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    eval_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    logging_strategy = 'steps',\n",
        "    logging_steps = 10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs = 3,\n",
        "    learning_rate = 2e-5,\n",
        "    warmup_steps = 100,\n",
        "    weight_decay = 0.01,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'eval_loss',\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    seed=42,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=0,\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  preds = np.argmax(predictions, axis = -1)\n",
        "  return {\n",
        "      'accuracy': accuracy_score(labels, preds),\n",
        "      'macro_f1': f1_score(labels, preds, average = 'macro'),\n",
        "      'weighted_f1': f1_score(labels, preds, average = 'weighted')\n",
        "  }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF-kHoYYLUQf",
        "outputId": "d502a67f-0a48-436f-cac3-2ac4828a9440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory = ./distilbert-finetuned-20251006-111927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Weight Calculation ---\n",
        "# Calculate class weights to handle class imbalance\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "print(\"Calculating class weights for imbalance handling....\")\n",
        "class_labels = np.unique(train_df['label'])\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=class_labels,\n",
        "    y=train_df['label'].values\n",
        ")\n",
        "# Convert weights to a PyTorch tensor\n",
        "class_weights_tensor = torch.tensor(weights, dtype=torch.float32).to(model.device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiSN4hSFMsmq",
        "outputId": "47a7704d-8eeb-4752-b16b-3988072fcd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating class weights for imbalance handling....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Trainer for Weighted Loss ---\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    \"\"\"Subclassing the Trainer to inject class weights into the CrossEntropyLoss function.\"\"\"\n",
        "    def __init__(self, *args, class_weights_tensor=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights_tensor = class_weights_tensor\n",
        "\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch\n",
        "        # Retrieve labels and remove them from inputs for the model forward pass\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        # Compute custom weighted loss\n",
        "        # The weight parameter in CrossEntropyLoss handles class imbalance by\n",
        "        # scaling the loss contribution of each class.\n",
        "        # Use self.class_weights_tensor\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights_tensor.to(logits.device))\n",
        "\n",
        "\n",
        "        # Calculate loss (logits: [batch_size, num_labels], labels: [batch_size])\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "HHjP8XyHMtjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Starting training\n",
        "print(\"Initializing WeightedLossTrainer and starting training ....\")\n",
        "trainer = WeightedLossTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset = val_ds,\n",
        "    compute_metrics = compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=1)],\n",
        "    class_weights_tensor=class_weights_tensor # Pass the tensor here\n",
        ")\n",
        "trainer.train()\n",
        "print('Training done ................')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "w0S4i9TgLVDf",
        "outputId": "8a0ae8e6-8945-4ce8-e851-70b305fbcac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing WeightedLossTrainer and starting training ....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 03:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.441300</td>\n",
              "      <td>1.367026</td>\n",
              "      <td>0.544000</td>\n",
              "      <td>0.335312</td>\n",
              "      <td>0.526502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.248100</td>\n",
              "      <td>1.268488</td>\n",
              "      <td>0.563500</td>\n",
              "      <td>0.413160</td>\n",
              "      <td>0.555385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.065300</td>\n",
              "      <td>1.234289</td>\n",
              "      <td>0.586500</td>\n",
              "      <td>0.440218</td>\n",
              "      <td>0.583363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done ................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Save model\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y1akKqHLXsv",
        "outputId": "e797a4a2-19e0-4c19-acee-d760b4f2f191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./distilbert-finetuned-20251006-111927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Evaluate on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "results = trainer.evaluate(test_ds)\n",
        "print(f\"Test results: {results}\")\n",
        "\n",
        "preds = trainer.predict(test_ds)\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "# Get true labels from the test_ds Dataset object\n",
        "y_true = test_ds['label']\n",
        "\n",
        "# Create a list of target names based on the classes present in the subset\n",
        "target_names = label_encoder.classes_[np.unique(y_true)]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use the label_encoder.classes_ for target names, but ensure they correspond to the classes in subset\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "print(\"Fine Tuning complaints on DistilBERT completed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "-oQlEG-7_tPg",
        "outputId": "6f9a8b48-06f6-4989-c955-0d1edc8b78ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results: {'eval_loss': 1.2850532531738281, 'eval_accuracy': 0.5895, 'eval_macro_f1': 0.4471136220536465, 'eval_weighted_f1': 0.5911367626628946, 'eval_runtime': 1.9582, 'eval_samples_per_second': 1021.34, 'eval_steps_per_second': 63.834, 'epoch': 3.0}\n",
            "\n",
            "Classification Report:\n",
            "                                                                              precision    recall  f1-score   support\n",
            "\n",
            "                                                     Bank account or service       0.41      0.21      0.28        75\n",
            "                                                 Checking or savings account       0.44      0.75      0.55        68\n",
            "                                                               Consumer Loan       0.14      0.16      0.15        50\n",
            "                                                                 Credit card       0.38      0.56      0.45        94\n",
            "                                                 Credit card or prepaid card       0.46      0.42      0.44       117\n",
            "                                                            Credit reporting       0.34      0.69      0.45       163\n",
            "Credit reporting, credit repair services, or other personal consumer reports       0.64      0.33      0.44       485\n",
            "                                                             Debt collection       0.81      0.73      0.77       444\n",
            "                          Money transfer, virtual currency, or money service       0.52      0.47      0.49        30\n",
            "                                                             Money transfers       0.55      0.67      0.60         9\n",
            "                                                                    Mortgage       0.93      0.89      0.91       280\n",
            "                                                     Other financial service       0.00      0.00      0.00         2\n",
            "                                                                 Payday loan       0.00      0.00      0.00        10\n",
            "                                   Payday loan, title loan, or personal loan       0.24      0.59      0.34        22\n",
            "                                                                Prepaid card       0.44      0.57      0.50         7\n",
            "                                                                Student loan       0.83      0.88      0.85       113\n",
            "                                                       Vehicle loan or lease       0.28      0.55      0.37        31\n",
            "\n",
            "                                                                    accuracy                           0.59      2000\n",
            "                                                                   macro avg       0.44      0.50      0.45      2000\n",
            "                                                                weighted avg       0.64      0.59      0.59      2000\n",
            "\n",
            "Fine Tuning complaints on DistilBERT completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a101ed"
      },
      "source": [
        "## Fine-tuning DistilBERT for Product Classification\n",
        "\n",
        "This section details the process and results of fine-tuning a pre-trained DistilBERT model for the consumer complaint product classification task. This represents our progression to state-of-the-art NLP techniques following experiments with traditional embeddings and attention-enhanced BiLSTM models.\n",
        "\n",
        "**Fine-tuning Process and Setup:**\n",
        "\n",
        "1.  **Data Preparation:** We utilized the previously prepared 20k sample dataset. Crucially, we filtered out product classes with fewer than 2 samples to enable stratified splitting, ensuring representative class distribution across training, validation, and test sets. The cleaned complaint narratives were used as input text.\n",
        "2.  **Label Encoding:** Product categories were encoded into numerical labels using `LabelEncoder`, ensuring compatibility with the model's output layer. The number of unique classes after filtering was 17.\n",
        "3.  **Tokenization:** The `DistilBertTokenizerFast` for `distilbert-base-uncased` was used to tokenize the complaint narratives. Sequences were truncated and padded to a maximum length of 128 tokens, as required by the DistilBERT model.\n",
        "4.  **Model Loading:** The `TFDistilBertForSequenceClassification` model pre-trained on `distilbert-base-uncased` was loaded. The output layer was configured to have `num_labels=17`, matching the number of classes in our filtered dataset.\n",
        "5.  **Training Arguments and Trainer:** We defined `TrainingArguments` to configure the fine-tuning process. Key parameters included:\n",
        "    *   `output_dir`: Directory for saving checkpoints and logs.\n",
        "    *   `eval_strategy` and `save_strategy`: Set to `'epoch'` to evaluate and save the model at the end of each training epoch.\n",
        "    *   `learning_rate`: A small learning rate (2e-5) is used, which is typical for fine-tuning to avoid rapidly overwriting the pre-trained knowledge.\n",
        "    *   `per_device_train_batch_size` and `per_device_eval_batch_size`: Set to 16.\n",
        "    *   `num_train_epochs`: Set to 3.\n",
        "    *   `load_best_model_at_end=True`: To load the model with the best validation performance after training.\n",
        "    *   `metric_for_best_model='eval_loss'`: Using validation loss to determine the best model.\n",
        "    *   `fp16=True`: Enabled for faster training on compatible hardware.\n",
        "    *   `report_to=None`: Disabled logging to external platforms like Weights & Biases.\n",
        "    *   An `EarlyStoppingCallback` with a patience of 1 was used to stop training if the validation loss did not improve for one epoch, preventing overfitting.\n",
        "6.  **Evaluation Metrics:** A `compute_metrics` function was defined to calculate Accuracy, Macro F1-score, and Weighted F1-score during evaluation.\n",
        "\n",
        "**Evaluation and Interpretation of Results:**\n",
        "\n",
        "The model was evaluated on the held-out test set. The key metrics are:\n",
        "\n",
        "*   **Test Accuracy: 0.5895** - This represents the overall proportion of correctly classified complaints. An accuracy of nearly 59% is a significant improvement over the previously attempted BiLSTM models (which achieved around 33% with class weights and 53% without), indicating the superior capability of the fine-tuned transformer model.\n",
        "*   **Macro F1-score: 0.4471** - The Macro F1-score is the unweighted average of the F1-scores for each class. It treats all classes equally, regardless of their size. A Macro F1 of 0.45 suggests that the model's performance varies significantly across different classes, and it likely struggles with the less frequent (minority) classes. If the model performed equally well on all classes, the Macro F1 would be closer to the overall accuracy. The discrepancy indicates that while the model is doing well on average across samples (accuracy), its performance is not balanced across different product categories.\n",
        "*   **Weighted F1-score: 0.5911** - The Weighted F1-score calculates the F1-score for each class and then averages them, weighted by the number of samples in each class. This metric is heavily influenced by the performance on larger (majority) classes. A Weighted F1 of 0.59, which is close to the overall accuracy, suggests that the model performs much better on the majority classes. The large difference between Macro and Weighted F1 confirms that the model is biased towards predicting the more frequent product categories.\n",
        "\n",
        "**Classification Report Breakdown:**\n",
        "\n",
        "The detailed classification report provides per-class metrics (precision, recall, F1-score, support). Observing the report (output in cell `-oQlEG-7_tPg`), we can see this bias:\n",
        "\n",
        "*   Classes like 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', and 'Mortgage' (which are likely majority classes based on the support counts) generally have higher precision, recall, and F1-scores.\n",
        "*   Conversely, many minority classes (e.g., 'Consumer Loan', 'Money transfer, virtual currency, or money service', 'Payday loan', 'Prepaid card', 'Vehicle loan or lease') have significantly lower or even zero precision and recall, resulting in very low or zero F1-scores. The model is likely failing to predict any samples for some of these rare classes.\n",
        "\n",
        "**Issues and Potential Refinements:**\n",
        "\n",
        "While the overall accuracy and weighted F1-score are encouraging and represent a significant improvement, the low Macro F1-score and the detailed classification report highlight that class imbalance is still a major challenge affecting the model's ability to generalize to less frequent product categories.\n",
        "\n",
        "Potential refinements to address the class imbalance and improve performance on minority classes include:\n",
        "\n",
        "*   **Class Weighting in Trainer:** Although we used a custom trainer for BiLSTM with class weights, the standard Hugging Face `Trainer` also supports `class_weight` directly if using a PyTorch model. If using a TensorFlow model, injecting weights into the loss function within a custom training loop or a subclassed `Trainer` (similar to what was attempted for the BiLSTM) would be necessary.\n",
        "*   **Oversampling Minority Classes:** Techniques like Random Oversampling or SMOTE could be applied to the training data to increase the number of samples in minority classes. Care must be taken to apply this only to the training set to avoid data leakage.\n",
        "*   **Undersampling Majority Classes:** Reducing the number of samples in majority classes in the training data can also help balance the dataset, though this might lead to losing valuable information.\n",
        "*   **Combining Oversampling and Undersampling:** Using a hybrid approach can be effective.\n",
        "*   **Exploring Different Metrics for Best Model:** While `eval_loss` is a common metric for saving the best model, you could experiment with using `'eval_macro_f1'` to explicitly optimize for better performance across all classes, even if it slightly reduces overall accuracy.\n",
        "*   **More Training Epochs:** While early stopping was used, perhaps slightly more training epochs with a larger patience could allow the model to learn more, provided it doesn't lead to overfitting.\n",
        "*   **Different Transformer Models:** Experimenting with other pre-trained transformer models (e.g., RoBERTa, ELECTRA) might yield better results.\n",
        "*   **Larger Dataset:** Fine-tuning on a larger subset of the original data (if computational resources allow) could provide more data for the model to learn from, especially for the less frequent classes.\n",
        "\n",
        "The fine-tuned DistilBERT model provides a strong foundation, but further efforts are needed to improve its ability to classify minority product categories effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, let's try fine tuning DistilBERT on the extended 350k samples that we have which can be a good headstart by adding more samples for rare classes**"
      ],
      "metadata": {
        "id": "KfFuSttAimIk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd52f909",
        "outputId": "2e1b7ae2-b7a9-46f1-d33b-fe01ef55ca8a"
      },
      "source": [
        "# Load the cleaned_data.parquet\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "load_path = '/content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major'\n",
        "cleaned_data = pd.read_parquet(os.path.join(load_path, 'cleaned_data.parquet'))\n",
        "\n",
        "print(\"Cleaned data loaded successfully.\")\n",
        "print(f\"Shape of cleaned data: {cleaned_data.shape}\")\n",
        "print(f\"Columns in cleaned data: {list(cleaned_data.columns)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cleaned data loaded successfully.\n",
            "Shape of cleaned data: (383512, 20)\n",
            "Columns in cleaned data: ['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue', 'Consumer complaint narrative', 'Company public response', 'Company', 'State', 'ZIP code', 'Tags', 'Consumer consent provided?', 'Submitted via', 'Date sent to company', 'Company response to consumer', 'Timely response?', 'Consumer disputed?', 'Complaint ID', 'narrative_length', 'cleaned_narrative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820ee898",
        "outputId": "282f1308-f0cb-46b2-d5ac-84c6af15f3dc"
      },
      "source": [
        "# data distribution (class counts) for the 'Product' column\n",
        "print(\"\\nProduct class distribution in cleaned data:\")\n",
        "product_counts_cleaned = cleaned_data['Product'].value_counts()\n",
        "print(product_counts_cleaned)\n",
        "print(f\"\\nNumber of unique product classes: {cleaned_data['Product'].nunique()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Product class distribution in cleaned data:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    92364\n",
            "Debt collection                                                                 86683\n",
            "Mortgage                                                                        52984\n",
            "Credit reporting                                                                31584\n",
            "Student loan                                                                    21809\n",
            "Credit card or prepaid card                                                     21379\n",
            "Credit card                                                                     18836\n",
            "Bank account or service                                                         14884\n",
            "Checking or savings account                                                     12881\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5745\n",
            "Money transfer, virtual currency, or money service                               5466\n",
            "Payday loan, title loan, or personal loan                                        4421\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of unique product classes: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "e81ae06d475241cd8d4f599dc2cbda84",
            "beeb27d35a2f448984add452d80b457a",
            "676c7f80717a4ce286d919c357749b41",
            "aebc27e9d1fa4156b28b86f64055d6ec",
            "4cd371a542ae4152b46f9e11879e580e",
            "49740c1212514de4891881d5096b77a1",
            "fc145f7d76954941a9ed19633b9d050d",
            "fdf2b866abd24d5b8076c9323fbe5181",
            "f82c73a9d169454f863c4b3bd06f09a6",
            "39c8085b3e2449f58055b7419e222540",
            "534bcb02b46447be93c74f65ddc79bc5"
          ]
        },
        "id": "50cbf04e",
        "outputId": "85329e22-a493-4c06-b1b5-46e2aff60cdc"
      },
      "source": [
        "# Preprocessing steps for fine-tuning (Label Encoding and Tokenization)\n",
        "\n",
        "# 1. Filter out classes with less than 2 samples for stratification (if needed for future splits)\n",
        "# Although we won't split the full dataset in this example, it's good practice\n",
        "# if you plan to split it for training/validation/testing.\n",
        "product_counts_cleaned = cleaned_data['Product'].value_counts()\n",
        "classes_to_keep_cleaned = product_counts_cleaned[product_counts_cleaned >= 2].index\n",
        "cleaned_data_filtered = cleaned_data[cleaned_data['Product'].isin(classes_to_keep_cleaned)].copy()\n",
        "\n",
        "print(f\"\\nShape of cleaned data after filtering for stratification: {cleaned_data_filtered.shape}\")\n",
        "print(f\"Product classes in filtered cleaned data: {cleaned_data_filtered['Product'].nunique()}\")\n",
        "\n",
        "\n",
        "# 2. Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datasets import ClassLabel, Features, Value # Import ClassLabel, Features, Value\n",
        "\n",
        "label_encoder_cleaned = LabelEncoder()\n",
        "# Fit the encoder on the product names present in the filtered cleaned data\n",
        "cleaned_data_filtered['label'] = label_encoder_cleaned.fit_transform(cleaned_data_filtered['Product'])\n",
        "num_labels_cleaned = len(label_encoder_cleaned.classes_)\n",
        "\n",
        "print(f\"\\nNumber of classes after encoding: {num_labels_cleaned}\")\n",
        "print(f\"Encoded label classes: {list(label_encoder_cleaned.classes_)}\")\n",
        "\n",
        "\n",
        "# 3. Tokenization (using the same tokenizer as for fine-tuning)\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from datasets import Dataset # Import Dataset\n",
        "\n",
        "print(\"\\nInitializing tokenizer ....\")\n",
        "# Using the same tokenizer as used for DistilBERT fine-tuning\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    if 'cleaned_narrative' not in batch:\n",
        "        raise ValueError(\"Batch does not contain 'cleaned_narrative' column.\")\n",
        "    return tokenizer(batch['cleaned_narrative'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "\n",
        "print(\"Tokenizing cleaned data ....\")\n",
        "# Create a Dataset object from the filtered cleaned data\n",
        "# Define features with ClassLabel for the 'label' column\n",
        "features = Features({\n",
        "    'cleaned_narrative': Value(dtype='string'),\n",
        "    'label': ClassLabel(names=list(label_encoder_cleaned.classes_))\n",
        "})\n",
        "# Reset the index before creating the Dataset to avoid index column issues\n",
        "cleaned_data_for_dataset = cleaned_data_filtered[['cleaned_narrative', 'label']].reset_index(drop=True)\n",
        "cleaned_ds = Dataset.from_pandas(cleaned_data_for_dataset, features=features)\n",
        "\n",
        "\n",
        "# Map the tokenization function over the dataset\n",
        "cleaned_ds = cleaned_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format to PyTorch tensors (or TensorFlow if you prefer for TF models)\n",
        "# We'll set it to PyTorch format as the previous fine-tuning used PyTorch Trainer\n",
        "cleaned_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\"Tokenization of cleaned data done.\")\n",
        "print(f\"Tokenized dataset columns: {cleaned_ds.column_names}\")\n",
        "print(f\"Label column feature type: {cleaned_ds.features['label']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of cleaned data after filtering for stratification: (383512, 20)\n",
            "Product classes in filtered cleaned data: 18\n",
            "\n",
            "Number of classes after encoding: 18\n",
            "Encoded label classes: ['Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Credit card', 'Credit card or prepaid card', 'Credit reporting', 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Mortgage', 'Other financial service', 'Payday loan', 'Payday loan, title loan, or personal loan', 'Prepaid card', 'Student loan', 'Vehicle loan or lease', 'Virtual currency']\n",
            "\n",
            "Initializing tokenizer ....\n",
            "Tokenizing cleaned data ....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/383512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e81ae06d475241cd8d4f599dc2cbda84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization of cleaned data done.\n",
            "Tokenized dataset columns: ['cleaned_narrative', 'label', 'input_ids', 'attention_mask']\n",
            "Label column feature type: ClassLabel(names=['Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Credit card', 'Credit card or prepaid card', 'Credit reporting', 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Mortgage', 'Other financial service', 'Payday loan', 'Payday loan, title loan, or personal loan', 'Prepaid card', 'Student loan', 'Vehicle loan or lease', 'Virtual currency'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification, # Import the model class\n",
        "    Trainer, # Import Trainer if used in this cell\n",
        "    TrainingArguments, # Import TrainingArguments if used in this cell\n",
        "    EarlyStoppingCallback # Import EarlyStoppingCallback if used in this cell\n",
        ")\n",
        "from datasets import Dataset, DatasetDict # Import Dataset and DatasetDict if used in this cell\n",
        "from sklearn.utils import class_weight # Import class_weight\n",
        "\n",
        "\n",
        "# 6. Load model\n",
        "print(\"Loading DistilBERT model ....\")\n",
        "# Use num_labels_cleaned from the preprocessing of the full dataset\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels_cleaned)\n",
        "\n",
        "# 7. Training arguments and trainer setup\n",
        "output_dir = f\"./distilbert-finetuned-full-data-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "print(f\"Output directory = {output_dir}\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    eval_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    logging_strategy = 'steps',\n",
        "    logging_steps = 10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs = 3,\n",
        "    learning_rate = 2e-5,\n",
        "    warmup_steps = 100,\n",
        "    weight_decay = 0.01,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'eval_loss',\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    seed=42,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=0,\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  preds = np.argmax(predictions, axis = -1)\n",
        "  return {\n",
        "      'accuracy': accuracy_score(labels, preds),\n",
        "      'macro_f1': f1_score(labels, preds, average = 'macro'),\n",
        "      'weighted_f1': f1_score(labels, preds, average = 'weighted')\n",
        "  }\n",
        "\n",
        "# Class Weight Calculation ---\n",
        "# Calculate class weights to handle class imbalance\n",
        "\n",
        "print(\"Calculating class weights for imbalance handling....\")\n",
        "# Calculate weights based on the labels in the full cleaned data before splitting\n",
        "# Access the 'label' column as a list or array from the Dataset object\n",
        "class_labels_full = cleaned_ds['label']\n",
        "# Convert to numpy array of integers explicitly for compute_class_weight\n",
        "y_for_weights = np.array(list(class_labels_full), dtype=int)\n",
        "\n",
        "weights_full = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_for_weights), # Use unique from the numpy array\n",
        "    y=y_for_weights # Use the numpy array for y\n",
        ")\n",
        "# Convert weights to a PyTorch tensor\n",
        "class_weights_tensor_full = torch.tensor(weights_full, dtype=torch.float32).to(model.device)\n",
        "\n",
        "# Custom Trainer for Weighted Loss ---\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    \"\"\"Subclassing the Trainer to inject class weights into the CrossEntropyLoss function.\"\"\"\n",
        "    def __init__(self, *args, class_weights_tensor=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights_tensor = class_weights_tensor\n",
        "\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch\n",
        "        # Retrieve labels and remove them from inputs for the model forward pass\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "\n",
        "        # Compute custom weighted loss\n",
        "        # The weight parameter in CrossEntropyLoss handles class imbalance by\n",
        "        # scaling the loss contribution of each class.\n",
        "        # Use self.class_weights_tensor\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights_tensor.to(logits.device))\n",
        "\n",
        "\n",
        "        # Calculate loss (logits: [batch_size, num_labels], labels: [batch_size])\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGo0EQGEDf8z",
        "outputId": "7220175f-ae90-4cd4-aef2-6c7810580401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DistilBERT model ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory = ./distilbert-finetuned-full-data-20251007-075339\n",
            "Calculating class weights for imbalance handling....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split cleaned_ds into train, val, and test sets for fine-tuning\n",
        "from datasets import DatasetDict\n",
        "\n",
        "print(\"Splitting cleaned data for fine-tuning ....\")\n",
        "\n",
        "# Use the tokenized cleaned_ds Dataset for splitting\n",
        "# Splitting the Dataset using datasets library's train_test_split\n",
        "# This returns a DatasetDict\n",
        "train_testvalid_full = cleaned_ds.train_test_split(test_size=0.2, stratify_by_column='label', seed=42)\n",
        "\n",
        "# Split the test_valid further into validation and test\n",
        "test_valid_full = train_testvalid_full['test'].train_test_split(test_size=0.5, stratify_by_column='label', seed=42)\n",
        "\n",
        "train_ds_full = train_testvalid_full['train']\n",
        "val_ds_full = test_valid_full['train']\n",
        "test_ds_full = test_valid_full['test']\n",
        "\n",
        "\n",
        "print(f\"Train set (full data): {len(train_ds_full)} samples\")\n",
        "print(f\"Validation set (full data): {len(val_ds_full)} samples\")\n",
        "print(f\"Test set (full data): {len(test_ds_full)} samples\")\n",
        "\n",
        "# 8. Starting training\n",
        "print(\"Initializing WeightedLossTrainer and starting training with full data....\")\n",
        "trainer = WeightedLossTrainer(\n",
        "    model = model, # Use the model initialized in the previous cell\n",
        "    args = training_args, # Use training_args from the previous cell\n",
        "    train_dataset = train_ds_full, # Use full training data\n",
        "    eval_dataset = val_ds_full, # Use full validation data\n",
        "    compute_metrics = compute_metrics, # Use compute_metrics from the previous cell\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=1)],\n",
        "    class_weights_tensor=class_weights_tensor_full # Pass the tensor for full data\n",
        ")\n",
        "trainer.train()\n",
        "print('Training done ................')\n",
        "\n",
        "# 9. Save model\n",
        "trainer.save_model(output_dir) # Use output_dir from the previous cell\n",
        "tokenizer.save_pretrained(output_dir) # Use tokenizer from preprocessing\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")\n",
        "\n",
        "# 10. Evaluate on test set\n",
        "print(\"Evaluating on test set (full data)...\")\n",
        "results_full = trainer.evaluate(test_ds_full) # Evaluate on full test data\n",
        "print(f\"Test results (full data): {results_full}\")\n",
        "\n",
        "\n",
        "preds_full = trainer.predict(test_ds_full) # Predict on full test data\n",
        "y_pred_full = np.argmax(preds_full.predictions, axis=1)\n",
        "# Get true labels from the test_ds_full Dataset object\n",
        "y_true_full = test_ds_full['label']\n",
        "\n",
        "# Use label_encoder_cleaned which was fitted on the full filtered data\n",
        "target_names_full = label_encoder_cleaned.classes_[np.unique(y_true_full)]\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (full data):\")\n",
        "print(classification_report(y_true_full, y_pred_full, target_names=target_names_full))\n",
        "\n",
        "print(\"Fine Tuning complaints on DistilBERT with full data completed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "XYT5Ic_4Df-8",
        "outputId": "a80bce51-9cb8-4bb0-99d7-a7364a7c76d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting cleaned data for fine-tuning ....\n",
            "Train set (full data): 306809 samples\n",
            "Validation set (full data): 38351 samples\n",
            "Test set (full data): 38352 samples\n",
            "Initializing WeightedLossTrainer and starting training with full data....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57528' max='57528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57528/57528 1:01:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.993600</td>\n",
              "      <td>1.021794</td>\n",
              "      <td>0.682173</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.686270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.641500</td>\n",
              "      <td>1.016793</td>\n",
              "      <td>0.695080</td>\n",
              "      <td>0.533470</td>\n",
              "      <td>0.698462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.623100</td>\n",
              "      <td>1.028906</td>\n",
              "      <td>0.709577</td>\n",
              "      <td>0.548920</td>\n",
              "      <td>0.714171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done ................\n",
            "Model and tokenizer saved to ./distilbert-finetuned-full-data-20251007-075339\n",
            "Evaluating on test set (full data)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (full data): {'eval_loss': 1.0231534242630005, 'eval_accuracy': 0.6932363370880267, 'eval_macro_f1': 0.5288980649847599, 'eval_weighted_f1': 0.6971259381336563, 'eval_runtime': 36.8424, 'eval_samples_per_second': 1040.974, 'eval_steps_per_second': 65.061, 'epoch': 3.0}\n",
            "\n",
            "Classification Report (full data):\n",
            "                                                                              precision    recall  f1-score   support\n",
            "\n",
            "                                                     Bank account or service       0.51      0.65      0.57      1489\n",
            "                                                 Checking or savings account       0.60      0.45      0.51      1288\n",
            "                                                               Consumer Loan       0.40      0.51      0.45       947\n",
            "                                                                 Credit card       0.46      0.69      0.55      1884\n",
            "                                                 Credit card or prepaid card       0.56      0.44      0.49      2138\n",
            "                                                            Credit reporting       0.42      0.78      0.54      3159\n",
            "Credit reporting, credit repair services, or other personal consumer reports       0.83      0.50      0.63      9237\n",
            "                                                             Debt collection       0.86      0.82      0.84      8669\n",
            "                          Money transfer, virtual currency, or money service       0.64      0.70      0.67       546\n",
            "                                                             Money transfers       0.56      0.44      0.49       149\n",
            "                                                                    Mortgage       0.94      0.93      0.93      5299\n",
            "                                                     Other financial service       0.00      0.00      0.00        29\n",
            "                                                                 Payday loan       0.35      0.47      0.40       175\n",
            "                                   Payday loan, title loan, or personal loan       0.38      0.53      0.45       442\n",
            "                                                                Prepaid card       0.54      0.81      0.65       145\n",
            "                                                                Student loan       0.82      0.93      0.87      2181\n",
            "                                                       Vehicle loan or lease       0.47      0.46      0.46       574\n",
            "                                                            Virtual currency       0.00      0.00      0.00         1\n",
            "\n",
            "                                                                    accuracy                           0.69     38352\n",
            "                                                                   macro avg       0.52      0.56      0.53     38352\n",
            "                                                                weighted avg       0.74      0.69      0.70     38352\n",
            "\n",
            "Fine Tuning complaints on DistilBERT with full data completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe655b68"
      },
      "source": [
        "## Fine-tuning DistilBERT on the Full Dataset\n",
        "\n",
        "Having explored initial models and fine-tuned DistilBERT on a smaller sample, we proceeded to fine-tune the DistilBERT model on the entire cleaned dataset to leverage its full potential and improve performance, especially on minority classes.\n",
        "\n",
        "**Process Highlights:**\n",
        "\n",
        "*   The full cleaned dataset was loaded, filtered to ensure classes had at least 2 samples for stratification, and then labeled encoded.\n",
        "*   The dataset was tokenized using the DistilBERT tokenizer with a max length of 128 and prepared as a `datasets.Dataset` with the 'label' column cast to `ClassLabel` for proper handling.\n",
        "*   The full dataset was split into training, validation, and test sets using stratified splitting to maintain class distribution.\n",
        "*   A `DistilBertForSequenceClassification` model was loaded with the appropriate number of output labels (18, reflecting the classes in the full filtered dataset).\n",
        "*   Balanced class weights were calculated for the full training set to address class imbalance during training, which was implemented using a custom `WeightedLossTrainer`.\n",
        "*   The model was fine-tuned for 3 epochs with early stopping based on validation loss.\n",
        "\n",
        "**Performance Evaluation (Full Dataset):**\n",
        "\n",
        "The model's performance was evaluated on the held-out test set, yielding the following key metrics:\n",
        "\n",
        "*   **Test Accuracy: 0.6932** - The overall proportion of correctly classified samples. This shows a significant improvement in overall accuracy compared to the fine-tuning on the 20k sample (0.5895), indicating that training on a larger dataset has helped the model generalize better.\n",
        "*   **Macro F1-score: 0.5289** - The unweighted average of F1-scores across all classes. This metric is a good indicator of the model's performance across both majority and minority classes, treating them equally. A Macro F1 of 0.53 is a notable improvement over the 20k sample result (0.4471), suggesting that the model is performing better on the less frequent classes when trained on the full dataset with class weights.\n",
        "*   **Weighted F1-score: 0.6971** - The average of F1-scores weighted by the number of samples in each class. This metric is heavily influenced by the performance on majority classes. A Weighted F1 of 0.70 is close to the overall accuracy, as expected, and also shows improvement over the 20k sample result (0.5911).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The results from fine-tuning on the full dataset with class weights demonstrate a substantial improvement across all key metrics compared to the previous attempts, including the fine-tuning on the smaller 20k sample.\n",
        "\n",
        "*   The higher **Test Accuracy** and **Weighted F1-score** indicate that the model is much better at classifying the majority classes when trained on more data.\n",
        "*   Crucially, the improved **Macro F1-score** suggests that the combined effect of using the full dataset and applying class weights has helped the model learn to classify minority classes more effectively, leading to a more balanced performance across all product categories.\n",
        "\n",
        "While there is still a gap between the Macro F1 and Weighted F1 (indicating that imbalance still poses a challenge, though less severe than before), the results are promising and demonstrate the power of fine-tuning on a larger, more representative dataset with appropriate techniques to handle imbalance.\n",
        "\n",
        "We have successfully fine-tuned a DistilBERT model on the full dataset, achieving significantly better performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae910b0a"
      },
      "source": [
        "## Merging Rare Product Classes\n",
        "\n",
        "To further address the class imbalance observed in the product categories, particularly the poor performance on classes with very few samples, we will merge some of the rare product classes into more frequent or related categories. This strategy aims to increase the number of training examples for the merged categories, potentially improving the model's ability to learn and classify these instances more effectively.\n",
        "\n",
        "Based on the class distribution and domain knowledge, the following merging strategy is applied:\n",
        "\n",
        "*   'Virtual currency' and 'Money transfers' are merged into 'Money transfer, virtual currency, or money service'.\n",
        "*   'Other financial service' is merged into 'Bank account or service'.\n",
        "*   'Prepaid card' is merged into 'Credit card or prepaid card'.\n",
        "*   'Payday loan' is merged into 'Payday loan, title loan, or personal loan'.\n",
        "*   'Consumer Loan' is merged into 'Vehicle loan or lease' (This merge is based on the assumption of some overlap or similarity in consumer complaints related to these loan types. This can be adjusted based on further analysis or domain expertise).\n",
        "\n",
        "The merging is performed by creating a mapping from the rare class names to their target merged class names and then using the `.replace()` method on the 'Product' column to create a new 'Product_merged' column. We will then examine the new class distribution to see the effect of the merging."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset, Features, Value, ClassLabel\n",
        "\n",
        "# 1. Load data\n",
        "print(\"1. Loading data...\")\n",
        "drive.mount('/content/drive')\n",
        "load_path = '/content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major'\n",
        "cleaned_data = pd.read_parquet(os.path.join(load_path, 'cleaned_data.parquet'))\n",
        "print(f\"Shape of cleaned data: {cleaned_data.shape}\")\n",
        "print(f\"Columns: {list(cleaned_data.columns)}\")\n",
        "print(\"\\nProduct class distribution:\")\n",
        "print(cleaned_data['Product'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbhpvncvSo0x",
        "outputId": "36161b7b-ac5b-4239-d189-19d3e8caf974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading data...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Shape of cleaned data: (383512, 20)\n",
            "Columns: ['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue', 'Consumer complaint narrative', 'Company public response', 'Company', 'State', 'ZIP code', 'Tags', 'Consumer consent provided?', 'Submitted via', 'Date sent to company', 'Company response to consumer', 'Timely response?', 'Consumer disputed?', 'Complaint ID', 'narrative_length', 'cleaned_narrative']\n",
            "\n",
            "Product class distribution:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    92364\n",
            "Debt collection                                                                 86683\n",
            "Mortgage                                                                        52984\n",
            "Credit reporting                                                                31584\n",
            "Student loan                                                                    21809\n",
            "Credit card or prepaid card                                                     21379\n",
            "Credit card                                                                     18836\n",
            "Bank account or service                                                         14884\n",
            "Checking or savings account                                                     12881\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5745\n",
            "Money transfer, virtual currency, or money service                               5466\n",
            "Payday loan, title loan, or personal loan                                        4421\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Merge rare classes\n",
        "print(\"2. Merging rare classes...\")\n",
        "merge_map = {\n",
        "    'Virtual currency': 'Money transfer, virtual currency, or money service',\n",
        "    'Other financial service': 'Bank account or service',\n",
        "    'Money transfers': 'Money transfer, virtual currency, or money service',\n",
        "    'Prepaid card': 'Credit card or prepaid card',\n",
        "    'Payday loan': 'Payday loan, title loan, or personal loan',\n",
        "    'Consumer Loan': 'Vehicle loan or lease'\n",
        "}\n",
        "cleaned_data['Product_merged'] = cleaned_data['Product'].replace(merge_map)\n",
        "print(\"Merged classes:\", merge_map)\n",
        "print(\"New class distribution:\\n\", cleaned_data['Product_merged'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVxSBQbSYSiR",
        "outputId": "8e2cdb41-3362-4fb6-b26c-5f845ef3bbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Merging rare classes...\n",
            "Merged classes: {'Virtual currency': 'Money transfer, virtual currency, or money service', 'Other financial service': 'Bank account or service', 'Money transfers': 'Money transfer, virtual currency, or money service', 'Prepaid card': 'Credit card or prepaid card', 'Payday loan': 'Payday loan, title loan, or personal loan', 'Consumer Loan': 'Vehicle loan or lease'}\n",
            "New class distribution:\n",
            " Product_merged\n",
            "Credit reporting, credit repair services, or other personal consumer reports    92364\n",
            "Debt collection                                                                 86683\n",
            "Mortgage                                                                        52984\n",
            "Credit reporting                                                                31584\n",
            "Credit card or prepaid card                                                     22829\n",
            "Student loan                                                                    21809\n",
            "Credit card                                                                     18836\n",
            "Vehicle loan or lease                                                           15219\n",
            "Bank account or service                                                         15176\n",
            "Checking or savings account                                                     12881\n",
            "Money transfer, virtual currency, or money service                               6979\n",
            "Payday loan, title loan, or personal loan                                        6168\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Filter classes with <2 samples\n",
        "print(\"3. Filtering classes with <2 samples...\")\n",
        "product_counts = cleaned_data['Product_merged'].value_counts()\n",
        "classes_to_keep = product_counts[product_counts >= 2].index\n",
        "cleaned_data_filtered = cleaned_data[cleaned_data['Product_merged'].isin(classes_to_keep)].copy()\n",
        "print(f\"Shape after filtering: {cleaned_data_filtered.shape}\")\n",
        "print(f\"Number of classes: {cleaned_data_filtered['Product_merged'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijcDbZx7YVAF",
        "outputId": "53cbc5de-6be8-4074-c528-48f0cbb604f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Filtering classes with <2 samples...\n",
            "Shape after filtering: (383512, 21)\n",
            "Number of classes: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Label encoding\n",
        "print(\"4. Label encoding...\")\n",
        "label_encoder = LabelEncoder()\n",
        "cleaned_data_filtered['label'] = label_encoder.fit_transform(cleaned_data_filtered['Product_merged'])\n",
        "num_labels = len(label_encoder.classes_)\n",
        "print(f\"Number of classes: {num_labels}\")\n",
        "print(f\"Label classes: {list(label_encoder.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D-_2F-XYYP3",
        "outputId": "6647e503-2de5-4ab6-a15d-5f62f0bb90ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Label encoding...\n",
            "Number of classes: 12\n",
            "Label classes: ['Bank account or service', 'Checking or savings account', 'Credit card', 'Credit card or prepaid card', 'Credit reporting', 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Money transfer, virtual currency, or money service', 'Mortgage', 'Payday loan, title loan, or personal loan', 'Student loan', 'Vehicle loan or lease']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Tokenization\n",
        "print(\"Initializing tokenizer...\")\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    if 'cleaned_narrative' not in batch:\n",
        "        raise ValueError(\"Batch does not contain 'cleaned_narrative' column.\")\n",
        "    return tokenizer(batch['cleaned_narrative'], truncation=True, padding='max_length', max_length=200)\n",
        "\n",
        "print(\"Tokenizing cleaned data...\")\n",
        "features = Features({\n",
        "    'cleaned_narrative': Value(dtype='string'),\n",
        "    'label': ClassLabel(names=list(label_encoder.classes_))\n",
        "})\n",
        "cleaned_data_for_dataset = cleaned_data_filtered[['cleaned_narrative', 'label']].reset_index(drop=True)\n",
        "cleaned_ds = Dataset.from_pandas(cleaned_data_for_dataset, features=features)\n",
        "cleaned_ds = cleaned_ds.map(tokenize_function, batched=True)\n",
        "cleaned_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "print(\"Tokenization done.\")\n",
        "print(f\"Tokenized dataset columns: {cleaned_ds.column_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "aa30d43cb84b4de68f2173a90e98eba3",
            "f1fe86f253794fc8ae62a8024fc1dcf8",
            "9288ca9ce04546f4b88201cbc840d7ab",
            "a9923c5fc85f43a2ba21a28c972e4363",
            "5ec0a3313c5a4bc2a868e175cbf1869a",
            "d07979f656c34293aa60cacc15477e1a",
            "16ef0930dfc641f1bfe6727c556c73e6",
            "669a411822c44e3d80ebec9bd49e236c",
            "aa600e2bc3dc427cbeaa1d2650e93809",
            "456a5d8e75e9410c8c200e657fc030d6",
            "3ba8f997ebac4bd09185ce1ce594d303"
          ]
        },
        "id": "lyLWDhTOYaGg",
        "outputId": "21ebec2f-7bae-4939-f771-493658555c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing tokenizer...\n",
            "Tokenizing cleaned data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/383512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa30d43cb84b4de68f2173a90e98eba3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization done.\n",
            "Tokenized dataset columns: ['cleaned_narrative', 'label', 'input_ids', 'attention_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Split data\n",
        "print(\"Splitting cleaned data for fine-tuning...\")\n",
        "train_testvalid = cleaned_ds.train_test_split(test_size=0.2, stratify_by_column='label', seed=42)\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, stratify_by_column='label', seed=42)\n",
        "train_ds = train_testvalid['train']\n",
        "val_ds = test_valid['train']\n",
        "test_ds = test_valid['test']\n",
        "print(f\"Train set: {len(train_ds)} samples\")\n",
        "print(f\"Validation set: {len(val_ds)} samples\")\n",
        "print(f\"Test set: {len(test_ds)} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HiNE1FbYdQd",
        "outputId": "39221984-b625-4681-805f-3f87e7071e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting cleaned data for fine-tuning...\n",
            "Train set: 306809 samples\n",
            "Validation set: 38351 samples\n",
            "Test set: 38352 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Load model\n",
        "print(\"Loading DistilBERT model...\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo9W-sg2YgjP",
        "outputId": "621f6060-46fb-4a13-d88e-570ddc28e0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DistilBERT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Compute class weights\n",
        "print(\"Calculating class weights...\")\n",
        "y_for_weights = np.array(cleaned_ds['label'], dtype=int)\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_for_weights), y=y_for_weights)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH7n02cBYii9",
        "outputId": "2186741b-da9b-4d03-9a2e-384db2d76242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating class weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Custom Trainer\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights_tensor=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights_tensor = class_weights_tensor\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights_tensor.to(logits.device))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "q22nzjEyYkX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Training arguments\n",
        "output_dir = os.path.join(load_path, f\"distilbert-finetuned-merged-{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_strategy='steps',\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_macro_f1',\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    seed=42,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=0\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=-1)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'macro_f1': f1_score(labels, preds, average='macro'),\n",
        "        'weighted_f1': f1_score(labels, preds, average='weighted')\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyntIocHYmVZ",
        "outputId": "9f032ee7-1923-4e38-bae8-423576fa6482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: /content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major/distilbert-finetuned-merged-20251008-060259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Start training\n",
        "print(\"Initializing WeightedLossTrainer and starting training...\")\n",
        "trainer = WeightedLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    class_weights_tensor=class_weights_tensor\n",
        ")\n",
        "trainer.train()\n",
        "print(\"Training done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "jm9DwhM8WpMO",
        "outputId": "e811f5c2-0ff0-4d9c-da32-ce1d0fed5c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing WeightedLossTrainer and starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57528' max='57528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57528/57528 1:23:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.851500</td>\n",
              "      <td>0.817943</td>\n",
              "      <td>0.690595</td>\n",
              "      <td>0.647663</td>\n",
              "      <td>0.690460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.777135</td>\n",
              "      <td>0.719043</td>\n",
              "      <td>0.674091</td>\n",
              "      <td>0.720365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.462000</td>\n",
              "      <td>0.801859</td>\n",
              "      <td>0.740320</td>\n",
              "      <td>0.688505</td>\n",
              "      <td>0.742916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Save model\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB7hq3kBYuQG",
        "outputId": "3bc2767c-287c-482b-e5aa-2bb6d734d189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/MyDrive/Data Science course/Major Projects/Projects/Smart Support NLP - Major/distilbert-finetuned-merged-20251008-060259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Evaluate on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "results = trainer.evaluate(test_ds)\n",
        "print(f\"Test results: {results}\")\n",
        "\n",
        "preds = trainer.predict(test_ds)\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "y_true = preds.label_ids\n",
        "target_names = label_encoder.classes_[np.unique(y_true)]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "print(\"Fine-tuning DistilBERT with merged classes completed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "ctBrRvuLYwQb",
        "outputId": "82ea9a3e-5e3b-4a69-beed-c075bd58f829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results: {'eval_loss': 0.8072065711021423, 'eval_accuracy': 0.7381883604505632, 'eval_macro_f1': 0.6866992855344299, 'eval_weighted_f1': 0.7406354100531907, 'eval_runtime': 52.9127, 'eval_samples_per_second': 724.816, 'eval_steps_per_second': 45.301, 'epoch': 3.0}\n",
            "\n",
            "Classification Report:\n",
            "                                                                              precision    recall  f1-score   support\n",
            "\n",
            "                                                     Bank account or service       0.55      0.54      0.54      1517\n",
            "                                                 Checking or savings account       0.57      0.58      0.57      1288\n",
            "                                                                 Credit card       0.51      0.64      0.57      1883\n",
            "                                                 Credit card or prepaid card       0.59      0.59      0.59      2283\n",
            "                                                            Credit reporting       0.51      0.71      0.59      3159\n",
            "Credit reporting, credit repair services, or other personal consumer reports       0.82      0.61      0.70      9237\n",
            "                                                             Debt collection       0.86      0.82      0.84      8669\n",
            "                          Money transfer, virtual currency, or money service       0.75      0.80      0.77       698\n",
            "                                                                    Mortgage       0.92      0.95      0.94      5299\n",
            "                                   Payday loan, title loan, or personal loan       0.50      0.65      0.57       616\n",
            "                                                                Student loan       0.83      0.93      0.88      2181\n",
            "                                                       Vehicle loan or lease       0.61      0.76      0.68      1522\n",
            "\n",
            "                                                                    accuracy                           0.74     38352\n",
            "                                                                   macro avg       0.67      0.72      0.69     38352\n",
            "                                                                weighted avg       0.76      0.74      0.74     38352\n",
            "\n",
            "Fine-tuning DistilBERT with merged classes completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9208a62"
      },
      "source": [
        "## Fine-tuning DistilBERT with Merged Product Classes\n",
        "\n",
        "This section presents the methodology and outcomes of fine-tuning a pre-trained DistilBERT model on the comprehensive dataset, incorporating a strategy of merging rare product classes to mitigate class imbalance and enhance classification performance. This represents a key advancement in our modeling approach, building upon previous experiments with traditional embeddings and initial transformer fine-tuning on a smaller subset.\n",
        "\n",
        "**Modeling Approach and Configuration:**\n",
        "\n",
        "The core of this phase involved leveraging the transfer learning capabilities of a pre-trained transformer model.\n",
        "\n",
        "*   **Base Model:** DistilBERT (specifically `distilbert-base-uncased`) was selected as the base architecture. DistilBERT is a smaller, faster, and lighter version of BERT, making it suitable for environments with computational constraints while retaining a significant portion of BERT's language understanding capabilities.\n",
        "*   **Task Adaptation:** The pre-trained DistilBERT model was adapted for sequence classification by adding a classification head (a linear layer) on top, configured to output probabilities for the target product classes.\n",
        "*   **Data Strategy:** The full cleaned dataset was utilized. Prior to model training, a critical data preprocessing step involved **merging rare product classes** into more frequent or semantically related categories. This reduced the number of distinct classes from 18 to 12, effectively increasing the sample size for the merged categories and creating a more favorable class distribution for training. The data was then split into stratified training, validation, and test sets to ensure representative class distribution across splits.\n",
        "*   **Tokenization:** The standard `DistilBertTokenizerFast` was used to tokenize the complaint narratives, applying truncation and padding to a fixed maximum sequence length of 200 tokens.\n",
        "*   **Class Imbalance Handling:** To further address the remaining class imbalance in the merged dataset, **balanced class weights** were calculated based on the distribution of samples in the training set. These weights were incorporated into the loss function during training using a custom `Trainer` implementation. This assigns higher penalties for misclassifications of minority class samples.\n",
        "*   **Training Configuration:** The model was fine-tuned using the Hugging Face `Trainer` with the following key `TrainingArguments`:\n",
        "    *   **Optimizer:** Adam with a small learning rate (2e-5), standard for fine-tuning to avoid disrupting pre-trained weights.\n",
        "    *   **Batch Size:** 16 per device for both training and evaluation.\n",
        "    *   **Epochs:** Trained for 3 epochs, with an `EarlyStoppingCallback` monitoring validation performance (specifically `eval_macro_f1`) with a patience of 2 epochs to prevent overfitting and select the best model.\n",
        "    *   **Evaluation and Saving Strategy:** Set to evaluate and save the model checkpoint at the end of each epoch (`eval_strategy='epoch'`, `save_strategy='epoch'`).\n",
        "    *   **Metric for Best Model:** `eval_macro_f1` was chosen as the metric to determine the best model to load at the end of training, prioritizing performance balance across all classes over overall accuracy.\n",
        "    *   **Other:** Warmup steps (50), weight decay (0.01), FP16 mixed precision for faster training, and a fixed random seed for reproducibility were also configured.\n",
        "\n",
        "**Evaluation and Performance Analysis:**\n",
        "\n",
        "The fine-tuned model was evaluated on the held-out test set. The key performance indicators provide insights into the model's effectiveness in classifying consumer complaints across the merged product categories.\n",
        "\n",
        "*   **Test Accuracy: 0.7382** - The overall accuracy indicates that approximately 73.8% of the test complaints were correctly classified into their respective merged product categories. This represents a substantial improvement compared to the fine-tuning on the unmerged 20k sample (0.5895) and the full unmerged data (0.6932).\n",
        "*   **Macro F1-score: 0.6867** - The Macro F1-score, which is the unweighted average of the F1-scores for each individual merged class, is a critical metric for evaluating performance on imbalanced datasets. A Macro F1 of 0.687 signifies a significant improvement over the previous fine-tuning attempts (0.4471 on 20k sample, 0.5289 on full unmerged data). This indicates that the merging strategy, combined with class weighting, has been effective in improving the model's ability to classify minority classes more accurately, leading to a more balanced performance across all categories.\n",
        "*   **Weighted F1-score: 0.7406** - The Weighted F1-score, which averages the F1-scores weighted by the number of samples in each class, is closer to the overall accuracy (0.7382). This metric is more influenced by the performance on the larger classes. A Weighted F1 of 0.741 suggests strong performance on the majority merged categories.\n",
        "\n",
        "**Classification Report Deep Dive:**\n",
        "\n",
        "The detailed classification report (output in cell `ctBrRvuLYwQb`) provides a per-class breakdown of precision, recall, and F1-score for the 12 merged classes. Analyzing this report reveals:\n",
        "\n",
        "*   **Improved Minority Class Performance:** Compared to the classification reports from fine-tuning on the unmerged data, the F1-scores for classes that were previously very rare have significantly improved. For example, categories like 'Money transfer, virtual currency, or money service', 'Payday loan, title loan, or personal loan', and 'Vehicle loan or lease' show much more respectable precision, recall, and F1-scores. This directly reflects the positive impact of merging and class weighting on the model's ability to handle less frequent cases.\n",
        "*   **Strong Performance on Majority Classes:** Classes like 'Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', and 'Mortgage' continue to exhibit high precision, recall, and F1-scores, benefiting from both a larger number of samples and the powerful features learned by the transformer model.\n",
        "*   **Balanced Performance:** The reduced gap between the Macro F1-score (0.687) and the Weighted F1-score (0.741) compared to previous models (e.g., 0.45 vs 0.59 on 20k sample) is a strong indicator that the model's performance is now much more balanced across all merged classes, rather than being heavily skewed towards the largest categories.\n",
        "\n",
        "**Conclusion of this Fine-tuning Phase:**\n",
        "\n",
        "The fine-tuning of DistilBERT on the full dataset with the implemented class merging strategy has yielded significantly improved and more balanced classification performance. The notable increase in Macro F1-score demonstrates the effectiveness of addressing class imbalance through data manipulation (merging) and weighted loss. This model represents the best performance achieved so far in this project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "981c446d"
      },
      "source": [
        "## Project Conclusion: End-to-End Consumer Complaint Classification\n",
        "\n",
        "This project successfully developed and evaluated several natural language processing models for classifying CFPB consumer complaints into product categories. The journey progressed from foundational techniques to state-of-the-art deep learning, showcasing an end-to-end approach to tackling a real-world text classification problem with imbalanced data.\n",
        "\n",
        "**Project Progression and Methodologies:**\n",
        "\n",
        "1.  **Data Preparation and Exploration:** The project began with loading, cleaning, and preprocessing consumer complaint narratives. Initial data exploration revealed the inherent class imbalance in the product categories, a key challenge addressed throughout the modeling phases.\n",
        "2.  **Traditional and Deep Learning Baselines:** Early modeling efforts established baselines using traditional embeddings (FastText) with a Feedforward Neural Network and a BiLSTM/CNN architecture. These models provided initial insights into the data complexity and the limitations of simpler approaches on this dataset, particularly concerning minority classes.\n",
        "3.  **Exploring Attention Mechanisms:** An attention layer was integrated with the BiLSTM model to investigate its impact on model focus and performance. Experiments with and without class weighting at this stage highlighted the complexities of handling imbalance with deep learning and the nuanced effects of weighting on overall vs. per-class performance.\n",
        "4.  **Advancing to Transformer Fine-tuning:** Recognizing the superior capabilities of modern large language models, the project transitioned to fine-tuning a pre-trained DistilBERT model. This marked a significant step, leveraging transfer learning to benefit from the extensive linguistic knowledge acquired during DistilBERT's pre-training.\n",
        "5.  **Addressing Imbalance with Full Data and Merging:** The fine-tuning was first performed on a smaller data sample and then scaled up to the full cleaned dataset. To further mitigate class imbalance, a data-centric strategy of merging rare product classes into more frequent, related categories was successfully implemented. Balanced class weights were incorporated during training on the merged dataset to ensure the model did not become overly biased towards majority classes.\n",
        "\n",
        "**Key Outcomes and Performance:**\n",
        "\n",
        "The fine-tuning of DistilBERT on the full dataset with merged classes and class weighting yielded the best performance metrics observed throughout the project. The improved **Macro F1-score** (0.687) compared to earlier models demonstrated a significant step towards more balanced performance across all product categories, including those that were previously rare. The high **Weighted F1-score** (0.741) and **Test Accuracy** (0.738) indicated strong overall classification capability, particularly for the more prevalent merged classes.\n",
        "\n",
        "**Demonstrated Skills:**\n",
        "\n",
        "This project effectively showcases a range of essential data science and NLP skills:\n",
        "\n",
        "*   **NLP Fundamentals:** Data cleaning, preprocessing, tokenization, and using word embeddings (FastText).\n",
        "*   **Deep Learning:** Building and experimenting with sequential models (BiLSTM), implementing custom layers (Attention), and understanding the effects of techniques like class weighting.\n",
        "*   **Transfer Learning & Fine-tuning:** Applying pre-trained transformer models (DistilBERT) to a specific downstream task.\n",
        "*   **Transformer Architectures:** Understanding the benefits and application of transformer-based models for complex NLP tasks.\n",
        "*   **Data Handling & Imbalance:** Strategies for handling large datasets, sampling, splitting data, and explicitly addressing class imbalance through data manipulation (merging) and algorithmic techniques (class weighting).\n",
        "*   **Model Evaluation and Interpretation:** Utilizing comprehensive metrics (Accuracy, Precision, Recall, F1-score, Macro/Weighted F1) and interpreting classification reports and confusion matrices to understand model strengths and weaknesses.\n",
        "*   **Iterative Development:** Progressing through different modeling approaches, evaluating results, and refining the strategy based on observations.\n",
        "\n",
        "**Final Thoughts:**\n",
        "\n",
        "The fine-tuned DistilBERT model with merged classes provides a robust solution for classifying consumer complaints. While opportunities for further refinement might exist (e.g., exploring other transformer models, different merging strategies), the current model represents a significant achievement in building an effective and more balanced classifier for this imbalanced text dataset. This project serves as a solid foundation for potential deployment or further exploration into aspects like model interpretability or real-time inference.\n",
        "\n",
        "This marks the conclusion of the development and evaluation phase of this consumer complaint classification project."
      ]
    }
  ]
}